{"cells":[{"cell_type":"markdown","metadata":{"id":"UwlFU-OL5wEI"},"source":["# Tarea 2 - Aprendizaje bayesiano\n","\n","### Grupo 36:\n","     - N. Farías\n","     - J. M. Varela"]},{"cell_type":"markdown","metadata":{"id":"7-LZ1PG56TEl"},"source":["## 1. Objetivo\n","\n","El objetivo de esta tarea es construir un predictor de palabras utilizando el algoritmo Naive Bayes.\n","\n","Es dificil definir una métrica con la cual cuantificar el éxito del aprendizaje. Por lo tanto, se utilizó la percepción como una forma subjetiva de determinar que la implementación es suficientemente buena, ya que en la mayoría de los casos predice palabras que tienen coherencia con lo escrito previamente.  \n","\n","Para comparar la calidad de las palabras sugeridas al entrenar el modelo con los distintos hiperparámetros, se utilizó su probabilidad ajustada para tener en cuenta la menor cantidad de términos en los N más bajos. Se plantean dos estrategias distintas para estimar el valor de esos términos faltantes."]},{"cell_type":"markdown","metadata":{"id":"ChdhWPCJLK8Q"},"source":["## La siguiente celda inicializa los datos de evaluación de rendimiento"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":413,"status":"ok","timestamp":1694657071227,"user":{"displayName":"Nicolás Farías","userId":"13782891472098886484"},"user_tz":180},"id":"akZwGsbSwOd6"},"outputs":[],"source":["probabilidades = {1: {1: [], 2: [], 3: [], 4: []}, 2: {1: [], 2: [], 3: [], 4: []}}"]},{"cell_type":"markdown","metadata":{"id":"qE3-gBqPxLTm"},"source":["## 2. Diseño"]},{"cell_type":"markdown","metadata":{"id":"JCXygKnvxS4M"},"source":["## 2.1 Limpieza de texto\n","\n","- Para el entrenamiento, se toma como entrada un archivo .txt generado por Whatsapp que contiene los mensajes de un chat grupal.\n","- Para eliminar la fecha, hora y emisor del mensaje, se considera únicamente el texto después del último \":\", si no hay \":\" en la línea, se ignora. Esto ocurre en los mensajes que contienen únicamente un archivo multimedia.\n","- Para todas las frases, ya sean de entrenamiento o ingresadas por el usuario: se pasan a minúscula, se eliminan los signos \",\", \";\", \"?\", \".\", \"!\", \"-\" y los tildes.\n","- Para el entrenamiento, se cruzan las palabras (luego de las transformaciones anteriores) con un diccionario en español para eliminar las que no estén."]},{"cell_type":"markdown","metadata":{"id":"qwEUi3MPHyN6"},"source":["## Ejecutar la siguiente celda para cargar el diccionario"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":774,"status":"ok","timestamp":1694655441192,"user":{"displayName":"Nicolás Farías","userId":"13782891472098886484"},"user_tz":180},"id":"tdmaBDTkcb5-","outputId":"7f9438fb-aa21-44ee-831c-de390d511f90"},"outputs":[{"name":"stdout","output_type":"stream","text":["El diccionario tiene 636598 palabras\n"]}],"source":["import urllib.request\n","\n","url = \"https://raw.githubusercontent.com/lorenbrichter/Words/master/Words/es.txt\"\n","nombre_archivo_diccionario = \"diccionario.txt\"\n","\n","try:\n","    urllib.request.urlretrieve(url, nombre_archivo_diccionario)\n","    with open(nombre_archivo_diccionario, 'r') as archivo:\n","      lineas = archivo.readlines()\n","\n","    # Elimino el fin de línea con strip()\n","    diccionario = {x.strip() for x in lineas}\n","    print(f\"El diccionario tiene {len(diccionario)} palabras\")\n","except Exception as e:\n","    print(f\"Ocurrió un error al descargar el archivo de diccionario: {e}\")"]},{"cell_type":"markdown","metadata":{"id":"UXYhwdC61G6B"},"source":["## 2.2 Algoritmo\n","\n","Se implementa el algoritmo Naive Bayes, cuyo entrenamiento consiste en calcular las probabilidades absolutas y condicionales de aparición de las palabras, a partir de la frecuencia y orden con el que aparecen en el documento utilizado para ese fin.\n","\n","El algoritmo toma como hiperparámetros:\n","- N: es la cantidad de palabras inmediatamente anteriores a tomar en cuenta para realizar la predicción.\n","- m: es la cantidad de instancias a agregar para hacer el cálculo del m-estimador, que se utiliza para evitar tener términos nulos cuando se está frente a una instancia no vista durante el entrenamiento.\n","\n","Algunas consideraciones de diseño sobre la implementación del algoritmo:\n","- El entrenamiento se realiza por frases. Luego de procesada la frase, se incrementa la variable del modelo donde se lleva el total de palabras procesadas.\n","- En los diccionarios P y PD, se almacena la cantidad de ocurrencias de las palabras, en lugar de su frecuencia. La frecuencia se calcula con una operación de división en tiempo de predicción. Esto simplifica la operación de reentrenamiento del modelo, dado que al cambiar la cantidad total de palabras (o la cantidad de ocurrencias de una palabra específica) no es necesario recalcular la frecuencia del resto de las palabras.\n","- La probabilidad p utilizada en la fórmula del m-estimador se calcula como 1 dividido la cantidad de palabras distintas. La cantidad de palabras distintas se calcula con la función len() de Python aplicada al diccionario P, la cual tiene costo computacional de orden constante. Por ese motivo se calcula al momento de recomendar, y consideramos innecesario precalcularla durante el entrenamiento."]},{"cell_type":"markdown","metadata":{"id":"0vq0hclKIJ5N"},"source":["## Ejecutar la siguiente celda para inicializar y entrenar el modelo\n","\n","* Es necesario definir correctamente el **nombre del archivo** que contendrá los chats para el entrenamiento.\n","\n","* Aquí también se pueden cambiar los **hiperparámetros** del modelo."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":790,"status":"ok","timestamp":1694655584996,"user":{"displayName":"Nicolás Farías","userId":"13782891472098886484"},"user_tz":180},"id":"KQvb7YafJb5r","outputId":"69343051-1c9a-4d8a-c4e1-dabeafff964b"},"outputs":[{"name":"stdout","output_type":"stream","text":["cantidad_total_palabras=142272\n","cantidad_palabras_distintas=11863\n"]}],"source":["#***************************** IMPORTANTE\n","NOMBRE_ARCHIVO_ENTRENAMIENTO = \"chats.txt\"\n","\n","# hiperparámetros\n","\n","# N define el horizonte de palabras hacia atrás que tomamos en cuenta\n","N = 3\n","\n","# m es el utilizado en la fórmula del m-estimador\n","m = 2\n","\n","# modelo\n","cantidad_total_palabras = 0\n","P = {}\n","PD = {}\n","\n","\n","def normalizar_palabra(palabra):\n","  for punt in [\",\", \";\", \"?\", \".\", \"!\", \"-\"]:\n","    palabra = palabra.replace(punt, \"\")\n","\n","  palabra = palabra.lower()\n","\n","  for k, v in {\"á\": \"a\", \"é\": \"e\", \"í\": \"i\", \"ó\": \"o\", \"ú\": \"u\"}.items():\n","    palabra = palabra.replace(k, v)\n","\n","  return palabra\n","\n","\n","def entrenar(palabras):\n","  # preproceso y normalizo las palabras\n","  palabras = [normalizar_palabra(w) for w in palabras]\n","\n","  # elimino palabras que no estén en el diccionario\n","  palabras = [w for w in palabras if w in diccionario]\n","\n","  for i, palabra in enumerate(palabras):\n","    P[palabra] = P.get(palabra, 0) + 1\n","    PD.setdefault(palabra, {})\n","    previas = set(palabras[max(0, i - N):i])\n","    for previa in previas:\n","      PD[palabra][previa] = PD[palabra].get(previa, 0) + 1\n","\n","  # retorno la cantidad de palabras procesadas\n","  return len(palabras)\n","\n","\n","# proceso el archivo de entrenamiento\n","with open(NOMBRE_ARCHIVO_ENTRENAMIENTO, 'r') as archivo:\n","  for linea in archivo:\n","    indice = linea.rfind(\":\")\n","    if indice != -1:\n","      documento = linea[indice + 1:]\n","      cantidad_total_palabras += entrenar(documento.split())\n","\n","print(f\"{cantidad_total_palabras=}\")\n","print(f\"cantidad_palabras_distintas={len(P)}\")"]},{"cell_type":"markdown","metadata":{"id":"-Kg3B7jm2tNL"},"source":["## 2.3 Evaluación\n","\n","- La evaluación de la implementación se realiza analizando la coherencia de la frase obtenida a partir de las predicciones del modelo.\n","- La comparación de calidad de predicciones entre modelos con distintos hiperparámetros se hace ajustando la probabilidad de la predicción obtenida, para equiparar las probabilidades de N más bajos con las de N más altos, considerando un valor máximo de N=4. El objetivo es que la productoria (sumatoria en nuestro caso por utilizar la función logaritmo) de las probabilidades condicionales P(d|h) tenga siempre la misma cantidad de términos (en este caso 4). De esta manera es como si todas las predicciones se hicieran considerando 4 palabras previas. El desafío está en estimar el valor de los términos faltantes, para lo cual se utilizan dos estrategias:\n","\n"," - **Estrategia 1**: asumimos que las palabras previas faltantes van a formar parte de las que fueron vistas como previas de h en los datos de entrenamiento. Por lo tanto, al momento de calcular las probabilidades de estas previas ficticias, estimamos el valor \"e\" para la fórmula del m-estimador como el promedio del valor \"e\" para todas las palabras que apoyan la hipótesis h. Esta suposición puede tener sentido si las frases escritas de alguna manera son consistentes con las frases de entrenamiento.\n","\n","  - **Estrategia 2**: hacemos el promedio de los términos calculados para las previas reales, y tomamos eso como estimación para los términos faltantes.\n","\n"," En ambos casos completamos la sumatoria para llegar a la cantidad de términos deseada. Cuanto mayor es la probabilidad ajustada promedio para una frase obtenida, mejor se considera la predicción.\n","\n"," Es importante notar que esta probabilidad ajustada se calcula únicamente a los efectos de la evaluación del modelo y se hace luego de que el algoritmo ya encontró el h_MAP. Es decir, no afecta el funcionamiento del modelo, más allá de agregar una pequeña penalización en el rendimiento computacional por los cálculos adicionales."]},{"cell_type":"markdown","metadata":{"id":"xEkzUTpaKyrh"},"source":["## La siguente celda contiene el programa principal para probar el predictor\n","\n","* El valor de la variable **MODO_EVALUACION** permite prender o apagar el modo de evaluación, de manera de poder evitar la penalización de rendimiento por los cálculos adicionales."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44539,"status":"ok","timestamp":1694641437127,"user":{"displayName":"Nicolás Farías","userId":"13782891472098886484"},"user_tz":180},"id":"VrHEaPPcj30i","outputId":"7ceeab76-7c4c-408f-80a3-19b20dd78dad"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ingrese la frase dando ENTER luego de \u001b[3mcada palabra\u001b[0m.\n","Ingrese sólo ENTER para aceptar la recomendación sugerida, o escriba la siguiente palabra y de ENTER\n","Ingrese '.' para comenzar con una frase nueva.\n","Ingrese '..' para terminar el proceso.\n",">> quiero\n","quiero \u001b[3mque\u001b[0m\n",">> \n","quiero que \u001b[3mno\u001b[0m\n",">> \n","quiero que no \u001b[3mse\u001b[0m\n",">> \n","quiero que no se \u001b[3mlo\u001b[0m\n",">> \n","quiero que no se lo \u001b[3mque\u001b[0m\n",">> \n","quiero que no se lo que \u001b[3mno\u001b[0m\n",">> \n","quiero que no se lo que no \u001b[3mse\u001b[0m\n",">> \n","quiero que no se lo que no se \u001b[3mlo\u001b[0m\n",">> \n","quiero que no se lo que no se lo \u001b[3mque\u001b[0m\n",">> .\n","----- Comenzando frase nueva -----\n",">> mañana\n","mañana \u001b[3mno\u001b[0m\n",">> es\n","mañana es \u001b[3mun\u001b[0m\n",">> la\n","mañana es la \u001b[3mde\u001b[0m\n",">> final\n","mañana es la final \u001b[3mde\u001b[0m\n",">> del\n","mañana es la final del \u001b[3mmundo\u001b[0m\n",">> \n","mañana es la final del mundo \u001b[3mque\u001b[0m\n",">> ..\n"]}],"source":["from math import log, inf, exp\n","\n","# 0: para apagar el modo evaluación\n","# 1: para prender el modo evaluación\n","MODO_EVALUACION = 1\n","\n","def m_estimador(e, n, p):\n","  return (e + m * p) / (n + m)\n","\n","def recomendacion_bayesiana(frase):\n","  cantidad_palabras_distintas = len(P)\n","  probabilidad_p = 1/cantidad_palabras_distintas\n","\n","  h_MAP = \"\"\n","  p_MAP = -inf\n","\n","  for h in P.keys():\n","    prob = log(P[h] / cantidad_total_palabras)\n","    terminos = []\n","    for d in frase[-N:]:\n","      d = normalizar_palabra(d)\n","      e = PD[h].get(d, 0)\n","      n = P[h]\n","      prob_m_estimador = log(m_estimador(e, n, probabilidad_p))\n","      prob = prob + prob_m_estimador\n","      terminos.append(prob_m_estimador)\n","\n","    if prob > p_MAP:\n","      h_MAP, p_MAP, terminos_MAP = h, prob, terminos\n","\n","\n","  if MODO_EVALUACION == 1:\n","    # Modo de evaluación activado\n","    cant_terminos = len(frase[-N:])\n","\n","    # Estrategia de evaluación 1\n","    e_norm = sum(PD[h_MAP].values()) / len(PD[h_MAP])\n","    n = P[h_MAP]\n","    m_estimador_norm = log(m_estimador(e_norm, n, probabilidad_p))\n","    p_MAP_norm = p_MAP + (4 - cant_terminos) * m_estimador_norm\n","    probabilidades[1][N].append(exp(p_MAP_norm))\n","\n","    # Estrategia de evaluación 2\n","    termino_norm = sum(terminos_MAP) / cant_terminos\n","    p_MAP_norm = p_MAP + (4 - cant_terminos) * termino_norm\n","    probabilidades[2][N].append(exp(p_MAP_norm))\n","\n","  return h_MAP\n","\n","\n","##### LOOP PRINCIPAL #####\n","\n","print(\"Ingrese la frase dando ENTER luego de \\x1b[3mcada palabra\\x1b[0m.\")\n","print(\"Ingrese sólo ENTER para aceptar la recomendación sugerida, o escriba la siguiente palabra y de ENTER\")\n","print(\"Ingrese '.' para comenzar con una frase nueva.\")\n","print(\"Ingrese '..' para terminar el proceso.\")\n","\n","frase = []\n","palabra_sugerida = \"\"\n","while 1:\n","    palabra = input(\">> \")\n","\n","    if palabra == \"..\":\n","      break\n","\n","    elif palabra == \".\":\n","      print(\"----- Comenzando frase nueva -----\")\n","      cantidad_total_palabras += entrenar(frase)\n","      frase = []\n","\n","    elif palabra == \"\": # acepta última palabra sugerida\n","      frase.append(palabra_sugerida)\n","\n","    else: # escribió una palabra\n","      frase.append(palabra)\n","\n","    if frase:\n","      palabra_sugerida = recomendacion_bayesiana(frase)\n","\n","      frase_propuesta = frase.copy()\n","      frase_propuesta.append(\"\\x1b[3m\"+ palabra_sugerida +\"\\x1b[0m\")\n","\n","      print(\" \".join(frase_propuesta))\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5C-WX7uBLa2n"},"source":["## La siguientes celdas se utilizan para mostrar el promedio de las probabilidades MAP ajustadas para los distintos valores del hiper parámetro N con ambas estrategias de evaluación"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":493,"status":"ok","timestamp":1694641457082,"user":{"displayName":"Nicolás Farías","userId":"13782891472098886484"},"user_tz":180},"id":"P1M2T1xD1Igk","outputId":"a5f8f7d0-38d3-408b-aca3-7a3eaaa70262"},"outputs":[{"name":"stdout","output_type":"stream","text":["Probabilidades promedio estrategia de evaluación 1\n","1:2.211419522795101e-08\n"]}],"source":["from statistics import mean\n","\n","print(\"Probabilidades promedio estrategia de evaluación 1\")\n","for k, v in probabilidades[1].items():\n","  if len(v) > 0:\n","    print(f\"{k}:{mean(v)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":421,"status":"ok","timestamp":1694641461193,"user":{"displayName":"Nicolás Farías","userId":"13782891472098886484"},"user_tz":180},"id":"sTGEwPxI6W1l","outputId":"72ffe248-9cb4-4301-9949-2326c518abc6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Probabilidades promedio estrategia de evaluación 2\n","1:4.628090502724307e-06\n"]}],"source":["from statistics import mean\n","\n","print(\"Probabilidades promedio estrategia de evaluación 2\")\n","for k, v in probabilidades[2].items():\n","  if len(v) > 0:\n","    print(f\"{k}:{mean(v)}\")"]},{"cell_type":"markdown","metadata":{"id":"N_HmGFko5pAv"},"source":["## Experimentación\n","\n","Se presentan a continuación los resultados obtenidos obtenidos al entrenar el modelo con un chat de alrededor de 42000 mensajes de un grupo de amigos, con distintos valores de N.\n","\n","En la primera prueba se comienza una frase con la palabra \"quiero\", y se acepta la predicción 8 veces seguidas. Luego de eso se utiliza el comando \".\" para reentrenar el modelo y comenzar la segunda prueba.\n","\n","En la segunda prueba se forma la frase \"mañana es la final del mundo\", aceptando la sugerencia cuando corresponda con la palabra deseada.\n","\n","Para cada valor de N, se muestra la frase obtenida de la primera prueba, así como también el promedio de la probabilidad ajustada para todas las predicciones del modelo.\n","\n","# N=1\n","Frase obtenida: \"quiero que no se lo que no se lo\"  \n","Estrategia 1: 2.211419522795101e-08  \n","Estrategia 2: 4.628090502724307e-06\n","\n","# N=2\n","Frase obtenida: \"quiero que gane el mundial de mayores finales de\"  \n","Estrategia 1: 4.31141515363044e-08  \n","Estrategia 2: 2.8782745626775494e-07\n","\n","# N=3\n","Frase obtenida: \"quiero que gane firmar el el el resto de\"  \n","Estrategia 1: 6.275309728061651e-07  \n","Estrategia 2: 1.418655788852198e-05\n","\n","# N=4\n","Frase obtenida: \"quiero que gane firmar firmar deslinde deslinde camilo camilo\"  \n","Estrategia 1: 2.742773675870112e-08  \n","Estrategia 2: 2.4789274118106713e-07"]},{"cell_type":"markdown","metadata":{"id":"8WUX4z79W95v"},"source":["## 4. Conclusión\n","\n","## 4.1 Resultados\n","\n","En la Tabla 1, se presenta un resumen de los resultados obtenidos para las distintas pruebas, con los distintos valores de N y ambas estrategias de evaluación."]},{"cell_type":"markdown","metadata":{"id":"Xd0PpaDRXC1D"},"source":["<table>\n","  <tr>\n","    <th>N</th>\n","    <th>Frase obtenida</th>\n","    <th>Estrategia 1</th>\n","    <th>Estrategia 2</th>\n","  </tr>\n","  <tr>\n","    <th>1</th>\n","    <td>quiero que no se lo que no se lo</td>\n","    <td>2.211419522795101e-08</td>\n","    <td>4.628090502724307e-06</td>\n","  </tr>    \n","  <tr>\n","    <th>2</th>\n","    <td>quiero que gane el mundial de mayores finales de</td>\n","    <td>4.31141515363044e-08</td>\n","    <td>2.8782745626775494e-07</td>\n","  </tr>\n","  <tr>\n","    <th>3</th>\n","    <td>quiero que gane firmar el el el resto de</td>\n","    <td>6.275309728061651e-07</td>\n","    <td>1.418655788852198e-05</td>\n","  </tr>\n","  <tr>\n","    <th>4</th>\n","    <td>quiero que gane firmar firmar deslinde deslinde camilo camilo</td>\n","    <td>2.742773675870112e-08</td>\n","    <td>2.4789274118106713e-07</td>\n","  </tr>\n","  <caption>Tabla 1 - Calidad de predicciones del modelo para cada valor de N</caption>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"B3HVZV598BVq"},"source":["En general se obtuvieron predicciones coherentes al principio, perdiendose un poco el sentido de la frase hacia el final. La mejor calidad de predicciones (según los resultados de las dos estrategias de evaluación) se dió en el caso de N=3, esto puede deberse a que analizar 3 palabras previas es un equilibrio entre considerar pocas palabras y no llegar a tomar todo el contexto, y tomar demasiadas palabras, donde algunas ya no aportan a lo que se quiere predecir.\n","\n","Al tomar N=1 lo que ocurre es que las probabilidades condicionales tienen el mismo peso en la sumatoria que la probabilidad absoluta. Por lo tanto empiezan a aparecer en las sugerencias muchos monosílabos que tienen una alta frecuencia absoluta en el texto de entrenamiento.\n","\n","Por otro lado con el valor de N=4 se observa con bastante frecuencia que una misma palabra se sugiere dos veces seguidas. Lo que ocurre es que a medida que se aumenta la ventana de contexto, menor es el peso relativo que tendrá la última palabra en el cálculo de las probabilidades. Por lo tanto, mayor será la probabilidad de que la última h_MAP siga siendo la mejor para este nuevo contexto.\n"]},{"cell_type":"markdown","metadata":{"id":"DppGpwWFXN4w"},"source":["### 4.2 Oportunidades de mejora\n","\n","- Se podrían obtener mejores resultados entrenando sobre un documento de mayor tamaño, ya que tendría más palabras en el diccionario P y combinaciones de palabras representadas por cada diccionario PD[h] disponibles a la hora de predecir.\n","\n","- En ocasiones la palabra sugerida por el modelo coincide con la última palabra de la frase. Dado que es muy raro que una palabra aparezca dos veces seguidas en una frase, se podría hacer un ajuste al algoritmo para evitar ese tipo de sugerencia, por ejemplo tomando la segunda palabra con mayor probabilidad en esos casos. Como se mencionó anteriormente, estas situaciones son particularmente notorias a medida que se aumenta el valor de N.\n","\n","- El diccionario utilizado no contiene palabras con tildes ni nombres propios, lo cual es una limitante para el vocabulario a predecir."]}],"metadata":{"colab":{"provenance":[{"file_id":"17N6vD-3xQ1TMwcK1jMNbPBawEJ_Ty3Q7","timestamp":1694355489746}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
